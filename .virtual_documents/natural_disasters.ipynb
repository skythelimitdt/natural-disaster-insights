


#import Dependencies
import pandas as pd
import os
from pathlib import Path
#new libarary used
import hashlib


#load excel file 
file_to_load = Path(".", "data","natural_disasters_data.xlsx")

#read the excel file 
natural_disasters_df = pd.read_excel(file_to_load)

#display the DataFrame
natural_disasters_df


#get info about total rows and columns
num_rows, num_columns = natural_disasters_df.shape

print(f"Total number of rows is: {num_rows}")
print(f"Total number of columns is: {num_columns}")


#gt info about data
natural_disasters_df.info()


#check for any null values
natural_disasters_df.isna().sum()


#drop column that contains all null values
natural_disasters_df = natural_disasters_df.drop("AID Contribution ('000 US$)", axis=1)


#check for any duplicates
natural_disasters_df[natural_disasters_df.duplicated()]


#fetch random rows
natural_disasters_df.sample(5)


#display columns
natural_disasters_df.columns.tolist()


#looks at the column Disaster Type and then Total Affected within each group and aggregaes the calculations for each
summary_stats_df = natural_disasters_df.groupby("Disaster Type")["Total Affected"].agg(["min", "max", "mean", "median", "var", "std", "sem"])

summary_stats_df


#defines function for row
def create_locationid(row):
#combine multiple column headers into a unique_string, concatonate values with _
    unique_string = f"{row['ISO']}_{row['Country']}_{row['Subregion']}_{row['Region']}_{row['Location']}"
#use hashlib to create unique identifiers for LocationID 
    return hashlib.md5(unique_string.encode()).hexdigest()
#apply function to  DataFrame
natural_disasters_df['LocationID'] = natural_disasters_df.apply(create_locationid, axis=1)

natural_disasters_df.columns.tolist()


#rename Total Damage ('000 US$) column
natural_disasters_df.rename(columns={"Total Damage ('000 US$)": "Total_Damage_000_USD"}, inplace=True)
#defines function for row
def create_impactid(row):
#combine multiple column headers into a unique_string, concatonate values with _
    unique_string = f"{row['DisNo.']}_{row['Total Deaths']}_{row['No. Injured']}_{row['No. Affected']}_{row['Total_Damage_000_USD']}"
#use hashlib to create unique identifiers for ImpactID 
    return hashlib.md5(unique_string.encode()).hexdigest()
#apply function to  DataFrame
natural_disasters_df['ImpactID'] = natural_disasters_df.apply(create_impactid, axis=1)

natural_disasters_df.columns.tolist()


#combine date columns into single column with date format
natural_disasters_df["Start Date"] = pd.to_datetime(
    natural_disasters_df[["Start Year", "Start Month", "Start Day"]].rename(
        columns={"Start Year": "year", "Start Month": "month", "Start Day": "day"}))

natural_disasters_df["End Date"] = pd.to_datetime(
    natural_disasters_df[["End Year", "End Month", "End Day"]].rename(
        columns={"End Year": "year", "End Month": "month", "End Day": "day"}))


natural_disasters_df


natural_disasters_df.info()


#sorty by Magnitude and display top 5
top_magnitude = natural_disasters_df.sort_values(["Magnitude"], ascending=False)

top_magnitude.head(5)


#sort by Magnitude and display bottom 5
bottom_magnitude = natural_disasters_df.sort_values(["Magnitude"], ascending=True)

bottom_magnitude.head(5)


#sort by Total Affected and display top 5
top_total_affected = natural_disasters_df.sort_values(["Total Affected"], ascending=False)

top_total_affected.head(5)


bottom_total_affected = natural_disasters_df.sort_values(["Total Affected"], ascending=True)

bottom_total_affected.head(5)


#total deaths and inujuries by disaster
total_deaths_injuries_by_disaster = (natural_disasters_df.groupby("Disaster Type")[["Total Deaths", "No. Injured"]]
    .sum().sort_values(by="Total Deaths", ascending=False).reset_index())

total_deaths_injuries_by_disaster


#find disaster with highest fatalities by year
highest_fatalities_by_year = (
    #finds the index of the row with the max Total Deaths for each year
    natural_disasters_df.loc[natural_disasters_df.groupby("Start Year")["Total Deaths"].idxmax()]
    [["Start Year", "Disaster Type", "Total Deaths", "Event Name", "Country"]]
    #sort total deaths in descending order
    .sort_values(by="Total Deaths", ascending=False))

highest_fatalities_by_year


#create disaster_events DataFrame
disaster_events_df = natural_disasters_df[["DisNo.", "Historic", "Classification Key", "Disaster Group", "Disaster Subgroup","Disaster Type", "Disaster Subtype", "External IDs", "Event Name", "Origin", "Associated Types", "Magnitude", "Magnitude Scale", "Start Date", "End Date"]]

disaster_events_df.head()


#get disaster_type count
disaster_type = disaster_events_df["Disaster Type"].value_counts()

disaster_type


#create locations DataFrame
locations_df = natural_disasters_df[["LocationID", "DisNo.", "ISO", "Country", "Subregion", "Region", "Location", "Latitude", "Longitude", "River Basin"]]

locations_df.head()


#get disaster_type count
location_count = locations_df["Location"].value_counts()

location_count


#create impact DataFrame
impact_df = natural_disasters_df[["ImpactID", "DisNo.", "Total Deaths", "No. Injured", "No. Affected", "No. Homeless", "Total Affected", "Reconstruction Costs ('000 US$)", "Reconstruction Costs, Adjusted ('000 US$)", "Insured Damage ('000 US$)", "Insured Damage, Adjusted ('000 US$)", "Total_Damage_000_USD", "Total Damage, Adjusted ('000 US$)", "CPI", "Admin Units", "Entry Date", "Last Update"]]

impact_df.head()


#create disaster_damage DataFrame
disaster_damage_df = natural_disasters_df[["ImpactID", "Total Deaths", "No. Injured", "No. Affected", "No. Homeless", "Total Affected", "Total_Damage_000_USD", "Total Damage, Adjusted ('000 US$)", "CPI"]]

disaster_damage_df.head()


#create disaster_response DataFrame
disaster_response_df = natural_disasters_df[["ImpactID", "OFDA/BHA Response", "Appeal", "Declaration"]]

disaster_response_df.head()


disaster_events_df.dtypes


locations_df.dtypes


impact_df.dtypes


disaster_damage_df.dtypes


disaster_response_df.dtypes


#export DataFrames as csv files
disaster_events_df.to_csv("resources/disaster_events.csv", index=False)

locations_df.to_csv("resources/locations.csv", index=False)

impact_df.to_csv("resources/impact.csv", index=False)

disaster_damage_df.to_csv("resources/disaster_damage.csv", index=False)

disaster_response_df.to_csv("resources/disaster_response_.csv", index=False)







